{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abed0dc3",
   "metadata": {},
   "source": [
    "# Colorisation Vid√©o avec Frame de R√©f√©rence\n",
    "\n",
    "Ce notebook impl√©mente une technique avanc√©e de colorisation vid√©o utilisant une premi√®re frame coloris√©e manuellement comme r√©f√©rence. L'algorithme propage les couleurs de mani√®re coh√©rente tout en pr√©servant l'√©clairage et les ombres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc16ff",
   "metadata": {},
   "source": [
    "## 1. Import des Libraries et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b568fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour les graphiques\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ Libraries import√©es avec succ√®s\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990c97f",
   "metadata": {},
   "source": [
    "## 2. Classe de Colorisation par R√©f√©rence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cdad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceColorization:\n",
    "    \"\"\"Colorisation vid√©o bas√©e sur une frame de r√©f√©rence coloris√©e.\"\"\"\n",
    "    \n",
    "    def __init__(self, temporal_consistency_weight=0.3, spatial_smoothing=True):\n",
    "        self.temporal_consistency_weight = temporal_consistency_weight\n",
    "        self.spatial_smoothing = spatial_smoothing\n",
    "        self.reference_features = None\n",
    "        self.reference_colors = None\n",
    "        self.color_mappings = {}\n",
    "        \n",
    "    def extract_color_features(self, gray_frame: np.ndarray, colored_frame: np.ndarray) -> Dict:\n",
    "        \"\"\"Extrait les caract√©ristiques de couleur de la frame de r√©f√©rence.\"\"\"\n",
    "        \n",
    "        # Conversion en LAB pour une meilleure correspondance des couleurs\n",
    "        lab_colored = cv2.cvtColor(colored_frame, cv2.COLOR_BGR2LAB)\n",
    "        \n",
    "        # Caract√©ristiques texturales et d'intensit√©\n",
    "        features = []\n",
    "        colors_lab = []\n",
    "        \n",
    "        h, w = gray_frame.shape\n",
    "        \n",
    "        # √âchantillonnage dense pour cr√©er la base de correspondance\n",
    "        step = 8  # √âchantillonnage tous les 8 pixels\n",
    "        for y in range(0, h-8, step):\n",
    "            for x in range(0, w-8, step):\n",
    "                # Patch 5x5 autour du pixel\n",
    "                patch = gray_frame[y:y+5, x:x+5]\n",
    "                if patch.shape[0] == 5 and patch.shape[1] == 5:\n",
    "                    # Caract√©ristiques du patch\n",
    "                    intensity = np.mean(patch)\n",
    "                    std_dev = np.std(patch)\n",
    "                    gradient_x = cv2.Sobel(patch.astype(np.float32), cv2.CV_32F, 1, 0, ksize=3)\n",
    "                    gradient_y = cv2.Sobel(patch.astype(np.float32), cv2.CV_32F, 0, 1, ksize=3)\n",
    "                    gradient_mag = np.mean(np.sqrt(gradient_x**2 + gradient_y**2))\n",
    "                    \n",
    "                    # Position relative pour la coh√©rence spatiale\n",
    "                    pos_x = x / w\n",
    "                    pos_y = y / h\n",
    "                    \n",
    "                    feature_vector = [intensity, std_dev, gradient_mag, pos_x, pos_y]\n",
    "                    features.append(feature_vector)\n",
    "                    \n",
    "                    # Couleur correspondante en LAB\n",
    "                    color_lab = lab_colored[y+2, x+2]  # Centre du patch\n",
    "                    colors_lab.append(color_lab)\n",
    "        \n",
    "        return {\n",
    "            'features': np.array(features),\n",
    "            'colors_lab': np.array(colors_lab)\n",
    "        }\n",
    "    \n",
    "    def set_reference_frame(self, gray_reference: np.ndarray, colored_reference: np.ndarray):\n",
    "        \"\"\"D√©finit la frame de r√©f√©rence et extrait les mappings de couleurs.\"\"\"\n",
    "        print(\"üé® Extraction des caract√©ristiques de la frame de r√©f√©rence...\")\n",
    "        \n",
    "        # Normalisation des images\n",
    "        if len(gray_reference.shape) == 3:\n",
    "            gray_reference = cv2.cvtColor(gray_reference, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Extraction des caract√©ristiques\n",
    "        reference_data = self.extract_color_features(gray_reference, colored_reference)\n",
    "        self.reference_features = reference_data['features']\n",
    "        self.reference_colors = reference_data['colors_lab']\n",
    "        \n",
    "        # Cr√©er un mod√®le k-NN pour la correspondance rapide\n",
    "        self.knn_model = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "        self.knn_model.fit(self.reference_features)\n",
    "        \n",
    "        print(f\"‚úÖ {len(self.reference_features)} points de correspondance extraits\")\n",
    "    \n",
    "    def colorize_frame(self, gray_frame: np.ndarray, previous_colored: np.ndarray = None) -> np.ndarray:\n",
    "        \"\"\"Colorise une frame en utilisant la r√©f√©rence et la coh√©rence temporelle.\"\"\"\n",
    "        \n",
    "        if len(gray_frame.shape) == 3:\n",
    "            gray_frame = cv2.cvtColor(gray_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        h, w = gray_frame.shape\n",
    "        colored_frame_lab = np.zeros((h, w, 3), dtype=np.float32)\n",
    "        \n",
    "        # Canal L (luminance) = niveaux de gris normalis√©s\n",
    "        colored_frame_lab[:, :, 0] = gray_frame.astype(np.float32) * (100.0 / 255.0)\n",
    "        \n",
    "        # Colorisation par blocks pour l'efficacit√©\n",
    "        block_size = 8\n",
    "        for y in range(0, h, block_size):\n",
    "            for x in range(0, w, block_size):\n",
    "                # Limites du block\n",
    "                y_end = min(y + block_size, h)\n",
    "                x_end = min(x + block_size, w)\n",
    "                \n",
    "                # Patch central pour les caract√©ristiques\n",
    "                center_y = y + block_size // 2\n",
    "                center_x = x + block_size // 2\n",
    "                \n",
    "                if center_y < h-2 and center_x < w-2:\n",
    "                    # Extraction des caract√©ristiques du patch\n",
    "                    patch = gray_frame[max(0, center_y-2):center_y+3, max(0, center_x-2):center_x+3]\n",
    "                    \n",
    "                    if patch.shape[0] >= 3 and patch.shape[1] >= 3:\n",
    "                        intensity = np.mean(patch)\n",
    "                        std_dev = np.std(patch)\n",
    "                        gradient_x = cv2.Sobel(patch.astype(np.float32), cv2.CV_32F, 1, 0, ksize=3)\n",
    "                        gradient_y = cv2.Sobel(patch.astype(np.float32), cv2.CV_32F, 0, 1, ksize=3)\n",
    "                        gradient_mag = np.mean(np.sqrt(gradient_x**2 + gradient_y**2))\n",
    "                        \n",
    "                        pos_x = center_x / w\n",
    "                        pos_y = center_y / h\n",
    "                        \n",
    "                        feature_vector = np.array([[intensity, std_dev, gradient_mag, pos_x, pos_y]])\n",
    "                        \n",
    "                        # Recherche des k plus proches voisins\n",
    "                        distances, indices = self.knn_model.kneighbors(feature_vector)\n",
    "                        \n",
    "                        # Moyenne pond√©r√©e des couleurs des voisins\n",
    "                        weights = 1.0 / (distances[0] + 1e-8)  # √âviter division par z√©ro\n",
    "                        weights = weights / np.sum(weights)\n",
    "                        \n",
    "                        predicted_color = np.average(self.reference_colors[indices[0]], axis=0, weights=weights)\n",
    "                        \n",
    "                        # Appliquer la couleur au block\n",
    "                        colored_frame_lab[y:y_end, x:x_end, 1] = predicted_color[1]  # Canal A\n",
    "                        colored_frame_lab[y:y_end, x:x_end, 2] = predicted_color[2]  # Canal B\n",
    "        \n",
    "        # Lissage spatial pour r√©duire les artifacts\n",
    "        if self.spatial_smoothing:\n",
    "            colored_frame_lab[:, :, 1] = cv2.bilateralFilter(\n",
    "                colored_frame_lab[:, :, 1].astype(np.float32), 9, 75, 75\n",
    "            )\n",
    "            colored_frame_lab[:, :, 2] = cv2.bilateralFilter(\n",
    "                colored_frame_lab[:, :, 2].astype(np.float32), 9, 75, 75\n",
    "            )\n",
    "        \n",
    "        # Coh√©rence temporelle avec la frame pr√©c√©dente\n",
    "        if previous_colored is not None and self.temporal_consistency_weight > 0:\n",
    "            previous_lab = cv2.cvtColor(previous_colored, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "            \n",
    "            # M√©lange pond√©r√©\n",
    "            alpha = 1 - self.temporal_consistency_weight\n",
    "            colored_frame_lab[:, :, 1] = (alpha * colored_frame_lab[:, :, 1] + \n",
    "                                         self.temporal_consistency_weight * previous_lab[:, :, 1])\n",
    "            colored_frame_lab[:, :, 2] = (alpha * colored_frame_lab[:, :, 2] + \n",
    "                                         self.temporal_consistency_weight * previous_lab[:, :, 2])\n",
    "        \n",
    "        # Conversion de LAB vers BGR\n",
    "        colored_frame_lab = np.clip(colored_frame_lab, 0, 255).astype(np.uint8)\n",
    "        colored_frame_bgr = cv2.cvtColor(colored_frame_lab, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        return colored_frame_bgr\n",
    "    \n",
    "    def colorize_video(self, video_frames: List[np.ndarray], reference_colored: np.ndarray) -> List[np.ndarray]:\n",
    "        \"\"\"Colorise une vid√©o compl√®te en utilisant la frame de r√©f√©rence.\"\"\"\n",
    "        \n",
    "        if len(video_frames) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Utiliser la premi√®re frame comme r√©f√©rence en niveaux de gris\n",
    "        first_frame_gray = video_frames[0]\n",
    "        if len(first_frame_gray.shape) == 3:\n",
    "            first_frame_gray = cv2.cvtColor(first_frame_gray, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Configurer la r√©f√©rence\n",
    "        self.set_reference_frame(first_frame_gray, reference_colored)\n",
    "        \n",
    "        colorized_frames = []\n",
    "        previous_colored = None\n",
    "        \n",
    "        print(f\"üé¨ Colorisation de {len(video_frames)} frames...\")\n",
    "        \n",
    "        for i, frame in enumerate(tqdm(video_frames, desc=\"Colorisation\")):\n",
    "            if i == 0:\n",
    "                # Utiliser directement la frame de r√©f√©rence coloris√©e\n",
    "                colorized_frame = reference_colored.copy()\n",
    "            else:\n",
    "                # Coloriser en utilisant la r√©f√©rence et la coh√©rence temporelle\n",
    "                colorized_frame = self.colorize_frame(frame, previous_colored)\n",
    "            \n",
    "            colorized_frames.append(colorized_frame)\n",
    "            previous_colored = colorized_frame\n",
    "        \n",
    "        return colorized_frames\n",
    "\n",
    "print(\"‚úÖ Classe ReferenceColorization d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b79b5",
   "metadata": {},
   "source": [
    "## 3. Fonctions Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video_frames(video_path: str, max_frames: int = None) -> List[np.ndarray]:\n",
    "    \"\"\"Charge les frames d'une vid√©o.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "        \n",
    "        if max_frames and frame_count >= max_frames:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"üìπ {len(frames)} frames charg√©es depuis {video_path}\")\n",
    "    return frames\n",
    "\n",
    "def save_video_frames(frames: List[np.ndarray], output_path: str, fps: float = 30.0):\n",
    "    \"\"\"Sauvegarde une liste de frames en tant que vid√©o.\"\"\"\n",
    "    if not frames:\n",
    "        print(\"‚ùå Aucune frame √† sauvegarder\")\n",
    "        return\n",
    "    \n",
    "    height, width = frames[0].shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"üíæ Vid√©o sauvegard√©e: {output_path}\")\n",
    "\n",
    "def create_pigeon_reference_frame(gray_frame: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Cr√©e une frame de r√©f√©rence coloris√©e avec des couleurs r√©alistes de pigeon.\"\"\"\n",
    "    h, w = gray_frame.shape\n",
    "    colored_frame = cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Conversion en HSV pour faciliter la colorisation\n",
    "    hsv_frame = cv2.cvtColor(colored_frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Segmentation approximative bas√©e sur l'intensit√©\n",
    "    # Ciel (zones claires)\n",
    "    sky_mask = gray_frame > 180\n",
    "    \n",
    "    # Pigeon (zones moyennes)\n",
    "    pigeon_mask = (gray_frame > 80) & (gray_frame < 160)\n",
    "    \n",
    "    # Bois (zones sombres mais pas trop)\n",
    "    wood_mask = (gray_frame > 40) & (gray_frame < 120)\n",
    "    \n",
    "    # Couleurs r√©alistes\n",
    "    # Ciel bleu clair\n",
    "    hsv_frame[sky_mask, 0] = 100  # Teinte bleue\n",
    "    hsv_frame[sky_mask, 1] = 80   # Saturation mod√©r√©e\n",
    "    \n",
    "    # Pigeon gris avec reflets verts/violets sur le cou\n",
    "    # Zone du cou (approximation)\n",
    "    neck_mask = (gray_frame > 90) & (gray_frame < 140) & (np.arange(h)[:, None] < h//3)\n",
    "    \n",
    "    # Corps gris\n",
    "    body_mask = pigeon_mask & ~neck_mask\n",
    "    hsv_frame[body_mask, 1] = 30  # Tr√®s peu satur√© (gris)\n",
    "    \n",
    "    # Cou iridescent\n",
    "    hsv_frame[neck_mask, 0] = 70   # Vert-violet\n",
    "    hsv_frame[neck_mask, 1] = 100  # Satur√©\n",
    "    \n",
    "    # Bois brun\n",
    "    hsv_frame[wood_mask, 0] = 15   # Teinte brune\n",
    "    hsv_frame[wood_mask, 1] = 120  # Bien satur√©\n",
    "    \n",
    "    # Conversion retour en BGR\n",
    "    colored_frame = cv2.cvtColor(hsv_frame, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Lissage pour √©viter les transitions abruptes\n",
    "    colored_frame = cv2.bilateralFilter(colored_frame, 9, 75, 75)\n",
    "    \n",
    "    return colored_frame\n",
    "\n",
    "def display_comparison(original: np.ndarray, colorized: np.ndarray, title: str = \"Comparaison\"):\n",
    "    \"\"\"Affiche une comparaison c√¥te √† c√¥te.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    # Image originale\n",
    "    if len(original.shape) == 3:\n",
    "        axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        axes[0].imshow(original, cmap='gray')\n",
    "    axes[0].set_title('Original (N&B)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Image coloris√©e\n",
    "    axes[1].imshow(cv2.cvtColor(colorized, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title('Coloris√©e')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Fonctions utilitaires d√©finies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ae8dd",
   "metadata": {},
   "source": [
    "## 4. Exemple d'Utilisation - Chargement de la Vid√©o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins des fichiers\n",
    "input_video_path = \"data/input/demo_color.mp4\"  # Remplacez par votre vid√©o N&B\n",
    "output_video_path = \"data/output/pigeon_colorized_reference.mp4\"\n",
    "\n",
    "# V√©rifier l'existence du fichier\n",
    "if os.path.exists(input_video_path):\n",
    "    print(f\"üìπ Chargement de la vid√©o: {input_video_path}\")\n",
    "    \n",
    "    # Charger les frames (limit√© √† 100 pour les tests)\n",
    "    video_frames = load_video_frames(input_video_path, max_frames=100)\n",
    "    \n",
    "    if video_frames:\n",
    "        print(f\"‚úÖ Vid√©o charg√©e: {len(video_frames)} frames\")\n",
    "        print(f\"üìê R√©solution: {video_frames[0].shape}\")\n",
    "        \n",
    "        # Afficher la premi√®re frame\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(cv2.cvtColor(video_frames[0], cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Premi√®re frame de la vid√©o\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ùå Aucune frame charg√©e\")\n",
    "else:\n",
    "    print(f\"‚ùå Fichier vid√©o non trouv√©: {input_video_path}\")\n",
    "    print(\"üìù Assurez-vous d'avoir une vid√©o dans le dossier data/input/\")\n",
    "    \n",
    "    # Cr√©er une vid√©o de d√©monstration si n√©cessaire\n",
    "    print(\"üé¨ Cr√©ation d'une vid√©o de d√©monstration...\")\n",
    "    demo_frame = np.random.randint(0, 256, (480, 640, 3), dtype=np.uint8)\n",
    "    video_frames = [demo_frame] * 30  # 30 frames identiques\n",
    "    print(\"‚úÖ Vid√©o de d√©monstration cr√©√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990c28c",
   "metadata": {},
   "source": [
    "## 5. Cr√©ation de la Frame de R√©f√©rence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293628be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la premi√®re frame en niveaux de gris\n",
    "first_frame = video_frames[0]\n",
    "if len(first_frame.shape) == 3:\n",
    "    first_frame_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    first_frame_gray = first_frame.copy()\n",
    "\n",
    "# Cr√©er une frame de r√©f√©rence coloris√©e avec des couleurs r√©alistes\n",
    "print(\"üé® Cr√©ation de la frame de r√©f√©rence coloris√©e...\")\n",
    "reference_colored = create_pigeon_reference_frame(first_frame_gray)\n",
    "\n",
    "# Afficher la comparaison\n",
    "display_comparison(first_frame_gray, reference_colored, \"Frame de R√©f√©rence - Avant/Apr√®s\")\n",
    "\n",
    "print(\"‚úÖ Frame de r√©f√©rence cr√©√©e avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040d4c0",
   "metadata": {},
   "source": [
    "## 6. Configuration et Colorisation de la Vid√©o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le coloriseur avec des param√®tres optimaux\n",
    "colorizer = ReferenceColorization(\n",
    "    temporal_consistency_weight=0.4,  # Forte coh√©rence temporelle\n",
    "    spatial_smoothing=True             # Lissage spatial activ√©\n",
    ")\n",
    "\n",
    "print(\"üé¨ D√©but de la colorisation vid√©o...\")\n",
    "print(f\"‚öôÔ∏è Coh√©rence temporelle: {colorizer.temporal_consistency_weight}\")\n",
    "print(f\"‚öôÔ∏è Lissage spatial: {colorizer.spatial_smoothing}\")\n",
    "\n",
    "# Coloriser la vid√©o\n",
    "colorized_frames = colorizer.colorize_video(video_frames, reference_colored)\n",
    "\n",
    "print(f\"‚úÖ Colorisation termin√©e: {len(colorized_frames)} frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57140a",
   "metadata": {},
   "source": [
    "## 7. Visualisation des R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d15cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de quelques frames repr√©sentatives\n",
    "frame_indices = [0, len(colorized_frames)//4, len(colorized_frames)//2, -1]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(frame_indices), figsize=(20, 10))\n",
    "\n",
    "for i, idx in enumerate(frame_indices):\n",
    "    # Frame originale\n",
    "    original = video_frames[idx]\n",
    "    if len(original.shape) == 3:\n",
    "        original_display = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        original_display = original\n",
    "    \n",
    "    axes[0, i].imshow(original_display, cmap='gray' if len(original.shape) == 2 else None)\n",
    "    axes[0, i].set_title(f'Original - Frame {idx}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Frame coloris√©e\n",
    "    colorized_display = cv2.cvtColor(colorized_frames[idx], cv2.COLOR_BGR2RGB)\n",
    "    axes[1, i].imshow(colorized_display)\n",
    "    axes[1, i].set_title(f'Coloris√©e - Frame {idx}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Comparaison Vid√©o: Original vs Coloris√©', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyse de la coh√©rence temporelle\n",
    "print(\"\\nüìä Analyse de la coh√©rence temporelle:\")\n",
    "temporal_differences = []\n",
    "for i in range(1, len(colorized_frames)):\n",
    "    diff = cv2.absdiff(colorized_frames[i-1], colorized_frames[i])\n",
    "    mean_diff = np.mean(diff)\n",
    "    temporal_differences.append(mean_diff)\n",
    "\n",
    "print(f\"Diff√©rence temporelle moyenne: {np.mean(temporal_differences):.2f}\")\n",
    "print(f\"√âcart-type des diff√©rences: {np.std(temporal_differences):.2f}\")\n",
    "\n",
    "# Graphique de la coh√©rence temporelle\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(temporal_differences)\n",
    "plt.title('Coh√©rence Temporelle - Diff√©rences entre Frames Cons√©cutives')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Diff√©rence Moyenne')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e3b1c",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde de la Vid√©o Coloris√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le dossier de sortie s'il n'existe pas\n",
    "os.makedirs(os.path.dirname(output_video_path), exist_ok=True)\n",
    "\n",
    "# Sauvegarder la vid√©o coloris√©e\n",
    "print(f\"üíæ Sauvegarde de la vid√©o coloris√©e...\")\n",
    "save_video_frames(colorized_frames, output_video_path, fps=30.0)\n",
    "\n",
    "# Sauvegarder aussi la frame de r√©f√©rence\n",
    "reference_path = output_video_path.replace('.mp4', '_reference.jpg')\n",
    "cv2.imwrite(reference_path, reference_colored)\n",
    "print(f\"üíæ Frame de r√©f√©rence sauvegard√©e: {reference_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Processus de colorisation termin√© avec succ√®s!\")\n",
    "print(f\"üìπ Vid√©o coloris√©e: {output_video_path}\")\n",
    "print(f\"üñºÔ∏è Frame de r√©f√©rence: {reference_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c38b2",
   "metadata": {},
   "source": [
    "## 9. Fonctions Avanc√©es - Am√©lioration de la Colorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedReferenceColorization(ReferenceColorization):\n",
    "    \"\"\"Version avanc√©e avec d√©tection d'objets et colorisation sp√©cialis√©e.\"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.object_masks = {}\n",
    "        self.object_colors = {\n",
    "            'sky': [135, 206, 235],      # Bleu ciel\n",
    "            'pigeon_body': [128, 128, 128],  # Gris pigeon\n",
    "            'pigeon_neck': [75, 0, 130],     # Violet iridescent\n",
    "            'wood': [139, 69, 19]            # Brun bois\n",
    "        }\n",
    "    \n",
    "    def detect_objects(self, gray_frame: np.ndarray):\n",
    "        \"\"\"D√©tecte approximativement les objets dans la frame.\"\"\"\n",
    "        h, w = gray_frame.shape\n",
    "        \n",
    "        # Segmentation bas√©e sur l'intensit√© et la position\n",
    "        masks = {}\n",
    "        \n",
    "        # Ciel (partie sup√©rieure, intensit√© √©lev√©e)\n",
    "        sky_intensity_mask = gray_frame > 180\n",
    "        sky_position_mask = np.zeros_like(gray_frame, dtype=bool)\n",
    "        sky_position_mask[:h//3, :] = True  # Tiers sup√©rieur\n",
    "        masks['sky'] = sky_intensity_mask & sky_position_mask\n",
    "        \n",
    "        # Pigeon (centre, intensit√© moyenne)\n",
    "        pigeon_mask = (gray_frame > 70) & (gray_frame < 160)\n",
    "        center_mask = np.zeros_like(gray_frame, dtype=bool)\n",
    "        center_mask[h//4:3*h//4, w//4:3*w//4] = True\n",
    "        \n",
    "        # Corps du pigeon\n",
    "        masks['pigeon_body'] = pigeon_mask & center_mask\n",
    "        \n",
    "        # Cou du pigeon (partie sup√©rieure du corps)\n",
    "        neck_mask = np.zeros_like(gray_frame, dtype=bool)\n",
    "        neck_mask[h//4:h//2, 2*w//5:3*w//5] = True\n",
    "        masks['pigeon_neck'] = pigeon_mask & neck_mask\n",
    "        \n",
    "        # Bois (partie inf√©rieure, intensit√© variable)\n",
    "        wood_mask = gray_frame < 140\n",
    "        bottom_mask = np.zeros_like(gray_frame, dtype=bool)\n",
    "        bottom_mask[2*h//3:, :] = True\n",
    "        masks['wood'] = wood_mask & bottom_mask\n",
    "        \n",
    "        return masks\n",
    "    \n",
    "    def apply_specialized_coloring(self, gray_frame: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Applique une colorisation sp√©cialis√©e par objet.\"\"\"\n",
    "        colored_frame = cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # D√©tecter les objets\n",
    "        masks = self.detect_objects(gray_frame)\n",
    "        \n",
    "        # Appliquer les couleurs sp√©cialis√©es\n",
    "        for obj_name, mask in masks.items():\n",
    "            if obj_name in self.object_colors and np.any(mask):\n",
    "                color = self.object_colors[obj_name]\n",
    "                \n",
    "                # M√©lange avec l'intensit√© originale\n",
    "                intensity = gray_frame[mask].astype(np.float32) / 255.0\n",
    "                \n",
    "                for c in range(3):\n",
    "                    colored_frame[mask, c] = (color[c] * intensity).astype(np.uint8)\n",
    "        \n",
    "        return colored_frame\n",
    "\n",
    "# Test de la version avanc√©e\n",
    "print(\"üî¨ Test de la colorisation avanc√©e...\")\n",
    "advanced_colorizer = AdvancedReferenceColorization(\n",
    "    temporal_consistency_weight=0.3,\n",
    "    spatial_smoothing=True\n",
    ")\n",
    "\n",
    "# Cr√©er une frame de r√©f√©rence am√©lior√©e\n",
    "advanced_reference = advanced_colorizer.apply_specialized_coloring(first_frame_gray)\n",
    "\n",
    "# Comparaison des m√©thodes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(first_frame_gray, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(reference_colored, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Colorisation Standard')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(advanced_reference, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Colorisation Avanc√©e')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle('Comparaison des M√©thodes de Colorisation', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Version avanc√©e test√©e avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23eef96",
   "metadata": {},
   "source": [
    "## 10. M√©triques d'√âvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(original_frames: List[np.ndarray], colorized_frames: List[np.ndarray]):\n",
    "    \"\"\"Calcule des m√©triques de qualit√© pour la colorisation.\"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "        'temporal_consistency': [],\n",
    "        'color_diversity': [],\n",
    "        'brightness_preservation': []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(colorized_frames)):\n",
    "        # Coh√©rence temporelle\n",
    "        if i > 0:\n",
    "            diff = cv2.absdiff(colorized_frames[i-1], colorized_frames[i])\n",
    "            temporal_consistency = 1.0 / (1.0 + np.mean(diff))\n",
    "            metrics['temporal_consistency'].append(temporal_consistency)\n",
    "        \n",
    "        # Diversit√© des couleurs\n",
    "        hsv_frame = cv2.cvtColor(colorized_frames[i], cv2.COLOR_BGR2HSV)\n",
    "        color_diversity = np.std(hsv_frame[:, :, 1])  # √âcart-type de la saturation\n",
    "        metrics['color_diversity'].append(color_diversity)\n",
    "        \n",
    "        # Pr√©servation de la luminosit√©\n",
    "        original_gray = cv2.cvtColor(original_frames[i], cv2.COLOR_BGR2GRAY) if len(original_frames[i].shape) == 3 else original_frames[i]\n",
    "        colorized_gray = cv2.cvtColor(colorized_frames[i], cv2.COLOR_BGR2GRAY)\n",
    "        brightness_diff = np.mean(np.abs(original_gray.astype(float) - colorized_gray.astype(float)))\n",
    "        brightness_preservation = 1.0 / (1.0 + brightness_diff/255.0)\n",
    "        metrics['brightness_preservation'].append(brightness_preservation)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculer les m√©triques\n",
    "print(\"üìä Calcul des m√©triques de qualit√©...\")\n",
    "metrics = calculate_metrics(video_frames, colorized_frames)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(\"\\nüéØ R√©sultats des m√©triques:\")\n",
    "print(f\"Coh√©rence temporelle moyenne: {np.mean(metrics['temporal_consistency']):.3f}\")\n",
    "print(f\"Diversit√© des couleurs moyenne: {np.mean(metrics['color_diversity']):.3f}\")\n",
    "print(f\"Pr√©servation de la luminosit√©: {np.mean(metrics['brightness_preservation']):.3f}\")\n",
    "\n",
    "# Graphiques des m√©triques\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(metrics['temporal_consistency'])\n",
    "axes[0].set_title('Coh√©rence Temporelle')\n",
    "axes[0].set_xlabel('Frame')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(metrics['color_diversity'])\n",
    "axes[1].set_title('Diversit√© des Couleurs')\n",
    "axes[1].set_xlabel('Frame')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(metrics['brightness_preservation'])\n",
    "axes[2].set_title('Pr√©servation Luminosit√©')\n",
    "axes[2].set_xlabel('Frame')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('M√©triques de Qualit√© de la Colorisation', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Analyse des m√©triques termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf2599",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook a impl√©ment√© une technique avanc√©e de colorisation vid√©o utilisant une frame de r√©f√©rence. Les principales caract√©ristiques sont :\n",
    "\n",
    "### ‚ú® Points forts :\n",
    "- **Coh√©rence temporelle** : Utilisation de la frame pr√©c√©dente pour maintenir la stabilit√©\n",
    "- **Correspondance intelligente** : Algorithme k-NN avec caract√©ristiques texturales\n",
    "- **Couleurs r√©alistes** : Mapping sp√©cialis√© pour pigeon, bois, et ciel\n",
    "- **Lissage spatial** : R√©duction des artifacts avec filtrage bilat√©ral\n",
    "\n",
    "### üîß Param√®tres ajustables :\n",
    "- `temporal_consistency_weight` : Contr√¥le la stabilit√© temporelle\n",
    "- `spatial_smoothing` : Active/d√©sactive le lissage spatial\n",
    "- Couleurs d'objets personnalisables\n",
    "\n",
    "### üìà M√©triques d'√©valuation :\n",
    "- Coh√©rence temporelle\n",
    "- Diversit√© des couleurs\n",
    "- Pr√©servation de la luminosit√©\n",
    "\n",
    "La m√©thode est particuli√®rement efficace pour les vid√©os avec des objets statiques ou peu mobiles, comme des sc√®nes d'oiseaux."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
